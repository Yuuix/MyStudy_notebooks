# 操作系统

## 1. 操作系统基本概念

`功能和目标：作为用户和计算机硬件之间的接口 `

**资源的管理者：**

处理器、存储器、文件、设备的管理

**向用户提供的功能：**

- 命令接口

  - 联机命令接口
  - 脱机命令接口

- 程序接口

  用户通过程序间接使用，由一组系统调用组成

- GUI

**操作系统的特征：**

- **并发**

  指两个或多个事件在同一时间间隔内交替发生

  操作系统的并发性指计算机系统中同时存在着多个运行着的程序

  > 区分：并行是指两个或多个事件在同一时刻同时发生

- **共享**

  资源共享，指系统中的资源可供内存中多个并发执行的进程共同使用。

  - 互斥共享方式（临界资源）

    系统中的某些资源，虽然可以提供给多个进程使用，但一个时间段内只允许一个进程访问该资源

    比如：不能同时使用QQ和微信进行视频聊天，同一时间段摄像头只能分配给一个进程

  - 同时共享方式

    系统中的某些资源，允许一个时间段内由多个进程”同时”对它们进行访问

    比如：可以同时使用QQ和微信访问硬盘资源发送文件

- **虚拟**

  指把一个物理上的实体变为若干个逻辑上的对应物。物理实体是实际存在的，而逻辑上对应物是用户感受到的。

  - 空分复用技术（如虚拟存储器技术）
  - 时分复用技术（如虚拟处理器）

- **异步**

  指在多道程序环境下，允许多个程序并发执行，但是由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。

**OS运行机制和体系结构**

**指令**

- 特权指令

  如内存清零指令，不允许用户程序使用

- 非特权指令

  如普通的运算指令

> CPU如何判读当前指令是否为特权指令呢？

**将处理器分为两种状态**

- 用户态（目态）

  此时CPU只能执行非特权指令

- 核心态（管态）

  特权指令，非特权指令都可执行

**两种程序**

- 内核程序

  系统的管理者，既可以执行特权指令，也可以执行非特权指令，运行在核心态

- 应用程序

  为了保证系统能安全运行，普通应用程序只能执行非特权指令，运行在用户态

**操作系统内核**

内核是计算机上配置的底层软件，是操作系统最基本最核心的部分

实现操作系统内核功能的那些程序就是内核程序

**中断和异常**

引入中断机制，实现了多道程序并发执行

本质：发生中断就意味着需要操作系统介入，开展管理工作

- 当中断发生时，CPU立即进入核心态
- 当中断发生后，当前运行的进程暂停运行，并由操作系统内核对中断进行处理
- 对于不同的中断信号，会进行不同的处理

发生了中断，就意味着需要操作系统介入，开展管理工作，由于操作系统的管理工作需要使用特权指令，因此CPU会从用户态转为核心态。中断可以使CPU从用户态切换为核心态，使得操作系统获得计算机的控制权。有了中断，才能实现多道程序并发执行。

> 用户态、核心态之间的切换是怎么实现的？
>
> 答：
>
> 用户态切换核心态是通过中断实现的，并且中断是唯一途径。
>
> 核心态切换到用户态是通过执行一个特权指令，将程序状态字的标志位设置为用户态。

- 内中断

  来源：CPU内部与当前执行的指令有关

- 外中断

  CPU外部与当前的指令无关

**系统调用**

“系统调用”是操作系统给应用程序（程序员/编程人员）使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以发出系统调用请求来获得操作系统的服务。

应用程序通过系统调用请求操作系统的服务。系统中的各种共享资源都由操作系统统一管理，因此在用户程序中，凡是与资源有关的操作，都必须通过系统调用的方式向操作系统提出服务请求，由操作系统代之完成。这样可以保证系统的稳定性和安全性，防止用户进行非法操作。

系统调用的相关处理需要在核心态下进行。

- 系统调用与库函数的区别

操作系统向上提供系统调用，编程语言向上提供库函数

普通应用程序可直接进行系统调用，也可以使用库函数，有的库函数涉及系统调用，有的不涉及。

- 系统调用背后的过程
  - 高级语言---编译--->汇编语言
  - 传入系统调用参数
  - 执行陷入指令（用户态）
  - 执行系统调用相应服务器程序（核心态）
  - 返回用户程序

## 2. CPU管理

**核心：操作系统如何管理好并发的多个进程，使多个进程可以有序的推进**

### 2.1 进程

#### 2.1.1 进程的定义、组成、组织方式、特征

程序：指令序列

早期的计算机（只支持单道程序）

程序的代码保存在程序段中，程序运行过程中处理的数据放在数据段中（如变量）

后来引入了多道程序技术后：为了方便操作系统管理，完成各程序并发执行，引入了进程、进程实体概念

> 内存中同时存放着多道程序，各个程序的代码、运算数据存放的位置不同。操作系统要怎么才能找到各程序存放的位置呢？
>
> 系统为每个运行的程序配置一个数据结构，称为进程控制块（PCB），用来描述进程的各种信息（如程序代码存放位置）

程序段、数据段、PCB三部分组成了进程实体（进程映像）。一般情况下，我们把进程实体就称之为进程，例如，所谓的创建进程，实质上是创建进程实体中的PCB；而撤销进程，实质上是撤销进程实体中的PCB。

**进程定义：**

- 进程是程序的一次执行过程
- 进程是一个程序及其数据在处理机上顺序执行时所发生的活动
- 进程是具有独立功能的程序在数据集合上运行的过程，它是系统进行资源分配的一个独立单位

进程是进程实体的运行过程，进程实体是静态的，进程是动态的

**进程三部分都存放着什么信息**

- 程序段：程序代码
- 数据段：程序运行时使用、产生的运算数据。如全局变量、局部变量、宏定义的常量等。
- PCB：操作系统通过PCB来管理进程，因此PCB中应该包含操作系统对其进行管理所需的各种信息。

**PCB包含哪些信息**

- 进程描述信息

  - 进程标识符PID，当进程被创建时，操作系统会为该进程分配一个唯一的ID，用于区分不同的进程
  - 用户标识符UID

- 进程控制和管理信息

  - 进程当前状态（运行态，就绪态，阻塞态等）
  - 进程优先级

- 资源分配清单

  - 程序段指针
  - 数据段指针
  - 键盘
  - 鼠标

- 处理机相关信息

  各种寄存器值

  当进程切换时需要把进程当前的运行情况记录下来保存在PCB中，如程序计数器的值表示了当前程序执行到了哪一步

**进程的组织**

在一个系统中，通常有数十、数百乃至数千个PCB。为了能对他们加以有效的管理，应该用适当的方式把这些PCB组织起来。

- 链接方式
  - 按照进程状态将PCB分为多个队列
  - 操作系统持有指向各个队列的指针
- 索引方式
  - 根据进程状态的不同，建立几张索引表
  - 操作系统持有指向各个索引表的指针

**进程的特征**

进程和程序是两个截然不同的概念，相比于程序，进程拥有以下特征：

- 动态性
- 并发性
- 独立性
- 异步性
- 结构性

#### 2.1.2 进程的状态与转换

进程是程序的一次执行。在这个执行过程中，有时进程正在被CPU处理，有时又需要等待CPU服务，可见，进程的状态是会有各种变化。

为了方便对各个进程的管理，操作系统需要将进程合理的划分为几种状态

**进程的三种状态**

- 运行态

  占有CPU，并在CPU上运行

- 就绪态

  已经具备运行条件，但由于没有空闲CPU，而暂时不能运行（万事俱备，只差CPU）

- 阻塞态

  因等待某一事件暂时不能运行

另外两种状态

- 创建态

  进程正在被创建，操作系统**为进程分配资源、初始化PCB**（创建进程的开销大）

- 终止态

  进程正在从系统中撤销，操作系统会**回收进程拥有的资源、撤销PCB**（撤销进程的开销大）

![在这里插入图片描述](assets/20190803142236911.png)

#### 2.1.3 进程控制

进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。

简化理解：反正进程控制就是要实现进程状态转换

**用原语实现进程控制**

原语的特点是执行期间不允许中断，只能一气呵成

这种不可被中断的操作即原子操作

原语采用“关中断指令”和“开中断指令”实现

**进程控制相关的原语**

进程控制会导致进程状态的转换，原语做的事情有：

- 更新PCB中的信息
- 将PCB插入合适的队列
- 分配/回收资源

**相关原语**

进程的创建、进程的终止、进程的阻塞、进程的唤醒、进程的切换

> 一些理解：当我们打开一个进程操作系统都做了哪些工作
>
> 比如：当我们打开QQ（一个进程）
>
> - 这时由操作系统通过高级调度，从外部后备队列中选择一个进程，例如：选择并创建一个进QQ进程（即创建一个PCB，通过原语操作实现）
>
> - 然后将该PCB插入到就绪队列中，等待为其分配CPU（此时该进程处于就绪态）
>
> - 这时操作系统需要采取特定的进程调度算法，从就绪队列中选择一个进程为其分配处理机资源
>
> - 当为该PCB分配了CPU资源后，操作系统根据PCB内关于该进程的信息管理该进程（此时处于运行态）
>
> - 一旦有某些进程优先级更高抢占CPU，QQ回到就绪态，这时涉及到了进程状态切换，需要操作系统执行某些原语操作（更改PCB信息，将PCB插入合适队列，回收资源）

#### 2.1.4 进程通信

指进程之间的信息交换

进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存空间地址空间相互独立。

为了保证安全，一个进程不能直接访问另一个进程的地址空间。

但是进程之间的信息交换又是必须实现的。为了保证进程间的安全通信，操作系统提供了一些方法。

**进程通信方式**

- 共享存储

  两个进程可以通过共享空间进行通信

  它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。

  两个进程对共享空间的访问必须是互斥的（互斥访问通过操作系统提供的工具实现）

  - 基于数据结构的共享
  - 基于存储区的共享

- 消息传递

  进程间的数据交换以格式化的消息为单位。进程通过操作系统提供的“发送消息/接收消息”两个原语进行数据交换。

  - 直接通信方式

    消息直接挂到接收方的消息队列里

  - 间接通信方式 

    先把消息发送到一个中间体（信箱）

- 管道通信

  管道是指用于连接读写进程的一个共享文件，又名pipe文件。其实就是在内存中开辟一个大小固定的缓存区。

  - 管道只能采用半双工通信，某一时间段内只能实现单向的传输。如果要实现双向同时通信，则需要设置两个管道。
  - 各进程需要互斥地访问管道
  - 数据以字符流的形式写入管道，当管道写满时，写进程的write()系统调用将被阻塞，等待读进程将数据取走。当读进程将数据全部取走后，管道变空，此时读进程的read()系统调用将被阻塞。
  - 如果没写满，不允许读，如果没读完，不允许写。
  - 数据一旦被读出，就从管道中被抛弃，这就意味着读进程最多只能有一个，否则可能会有读错数据的情况。

### 2.2 线程

#### 2.2.1 线程概念、多线程模型

进程的引入使得计算机可以在统一时间段内处理多个任务（交替执行）

但是在一个任务中还可能包含很多小的任务，传统的进程模型不能保证这些小的子任务同时进行

所以引入多线程，可以使得一个进程包含多个线程，而CPU可以同时执行多个线程

==线程是基本的CPU执行单元，程序执行流的最小单位==

**引入线程带来的变化**

- 资源分配与调度
- 并发度提高
- 系统开销小（共享内存地址空间）
- 通信更加容易

**线程的属性**

。。。

**线程的实现方式**

- 用户级线程

  用户级线程由应用程序通过**线程库**实现。所有的线程管理工作都由应用程序负责（包括线程切换）

  用户级线程中，线程切换可以在用户态下即可完成，不需要操作系统的干预。

  在用户看来，是有多个线程，但在操作系统看来，并意识不到线程的存在。

  用户级线程就是**“从用户视角看能看到的线程”**

- 内核级线程

  内核级线程的管理工作由操作系统内核完成。线程调度、切换等工作都由内核负责，因此**内核级线程的切换必然需要在核心态下才能完成。**

  **内核级线程就是从操作系统内核视角看能看到的线程**
  
  ![用户级线程和内核级线程，你分清楚了吗？](assets/20191120165419535.png)

==内核级线程才是处理机分配的单位==

> 例如：
>
> 有三个用户级线程映射到两个内核级线程，该进程在4核处理机的计算机上运行
>
> 最对只有两个用户线程并行执行

- 多线程模型

  在同时支持用户级线程和内核级线程的系统中，由几个用户级线程映射到几个内核级线程的问题

  - 多对一模型

    优点：用户级线程的切换在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高

    缺点：当一个用户线程被阻塞后，整个进程都会被阻塞，并发度不高。多个线程不可在多核处理器上并行运行

  - 一对一模型

    优点：当一个线程阻塞后，别的线程还可以继续执行，并发能力强。多线程可在多核处理器上并行执行。

    缺点：一个用户级进程会占用多个内核级线程，线程切换由操作系统的内核完成，需要切换到核心态，因此线程管理的成本高，开销大。

  - 多对多模型 (n个用户级线程映射到m个内核级线程n >= m)

    每个用户级进程对应m个进程（前两个模型的折中）

    优点：克服了多对一模型并法度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。

### 2.3 处理机调度

#### 2.3.1 处理机调度的概念、层次

==当有一堆任务要处理，但由于资源有限，这些事情没法同时处理。这就需要确定某种规则来决定处理这些任务的顺序，这就是调度研究的问题。==

在多道程序系统中，进程的数量往往是多于处理机个数的，这样不可能同时并行的处理各个进程。

**处理机调度**

就是从就绪队列中按照一定的算法选择一个进程并将处理机分配给它运行，以实现进程的并发执行。

**调度的三个层次**

- 高级（作业）调度（主要解决的是调入的问题）

  `外存-->内存`

  按一定的原则从外存上处于后备队列的作业中挑选一个（或多个）作业，给他们分配内存等必要资源，并建立相应的进程（建立PCB），以使他们获得竞争处理机的权利。

  高级调度是辅助（外存）与内存之间的调度。每个作业只调入一次，调出一次。

  作业调入时会建立相应的PCB，作业调出时才撤销PCB。高级调度主要是指调入的问题，因为只有调入的时机需要操作系统来确定，但调出的时机必然是作业运行结束才调出。

- 中级（内存）调度

  `外存-->内存`

  引入了**虚拟存储技术**之后，可将暂时不能运行的进程调至外存等待。等他重新具备了运行条件且内存又稍有空闲时，再重新调入内存。

  采用这种策略，可以提高内存利用率和系统吞吐量。

  暂时调到外存等待的进程状态为挂起状态。值得注意的是，PCB并不会一起调到外存，而是会常驻内存。PCB中会记录进程在外存中的存放位置，进程状态等待信息，操作系统通过内存中的PCB来保持对各个进程的监管、管理。被挂起的进程PCB会被放到挂起队列中。

  中级调度，就是要决定将哪个处于挂起状态的进程重新调入内存。

  一个进程可能会被多次调出、调入内存，因此中级调度发生的频率要比高级调度更高。

> 进程的挂起态与七状态模型

- 低级（进程）调度

  `内存-->CPU`

  其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理机分配给它。

  进程调度是操作系统中==最基本==的一种调度，在一般的操作系统中都必须配置进程调度。

  进程调度的频率很高，一般几十毫秒一次。

#### 2.3.2 进程调度的时机、切换与过程、方式

**进程调度的时机**

进程调度（低级调度）：就是按照某种算法从就绪队列中选择一个进程为其分配处理机。

**需要进行进程调度与切换的情况**

- 当前运行的进程主动放弃处理机
- 当前运行的进程被动放弃处理机

**进程调度的方式**

- 非剥夺调度方式，又称非抢占方式。即只允许程序主动放弃处理机。在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态。
- 剥夺调度方式，又称抢占方式。当一个进程正在处理机上执行时，如果有一个更重要或紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给更重要紧迫的那个进程。

**狭义的进程调度和广义的进程调度**

- 狭义的进程调度指的是从就绪队列中选择一个要运行的进程。（这个进程可以是刚刚被暂停执行的进程，也可能是另一个进程，后一种情况需要进程切换）

  进程切换是指一个进程让出处理机，另一个进程占用处理机的过程。

- 广义的进程调度包含了选择一个进程和进程切换两个步骤

**进程的切换主要完成**

- 对原来运行进程各种数据的保存
- 对新的进程各种数据的恢复

进程调度、切换是有代价的，并不是调度越频繁，并发度就越高

#### 2.3.3 调度算法的评价指标

**CPU利用率**

指CPU忙碌的时间占总时间的比例

利用率=忙碌的时间/总时间

**系统吞吐量**

对于计算机来说，希望能用尽可能少的时间处理完尽可能多的作业

系统吞吐量：单位时间完成作业的数量

系统吞吐量=总共完成了多少道作业/总共花了多少时间

**周转时间**

指从作业被提交给系统开始，到作业完成为止的这段时间间隔

包括四部分：

1. 作业在外存后备队列上等待作业调度（高级调度）的时间

2. 进程在就绪队列中等待进程调度（低级调度）的时间

3. 进程在CPU上执行的时间

4. 进程等待I/O操作完成的时间

后三项在一个作业的整个过程中，可能发生多次

`周转时间=作业完成时间-作业提交时间`

`平均周转时间=各作业周转时间之和/作业数`

`带权周转时间=作业周转时间/作业实际运行的时间`（越小用户体验越好）

`平均带权周转时间=各作业带权周转时间之和/作业数`

**等待时间**

指进程/作业处于等待处理机状态时间之和，等待时间越长，用户体验越差

**响应时间**

指用户提交请求到首次产生响应所用的时间

#### 2.3.4 调度算法（早期批处理系统）

**先来先服务（FCFS）**

- 算法思想

  主要从公平的角度考虑（类似于我们生活中排队买东西的例子）

- 算法规则

  按照作业/进程到达的先后顺序进行服务

- 用于作业/进程调度

  用于作业调度时：考虑的是哪个作业先到达后备队列

  用于进程调度时：考虑的是哪个进程先到达就绪队列

- 是否可抢占

  非抢占式的算法

- 优缺点

  优点：公平，算法实现简单

  缺点：排在长作业后面的短作业需要等待很长时间，带权周转时间很大，对短作业用户体验不好。即此方法对长作业有利，短作业不利

- 是否会导致饥饿

  `指某进程长期得不到服务`

  不会

**短作业优先（SJF）**

- 算法思想

  追求最少的等待时间，最少的平均周转时间，最少的平均带权周转时间

- 算法规则

  最短的作业/进程优先得到服务（服务时间最短）

- 用于作业/进程调度

  既可用于作业调度，也可用于进程调度。用于调度时称为“短作业优先算法”

- 是否可抢占

  非抢占式算法。但也有抢占式的版本，最短剩余时间优先算法。

  短时间优先：每次调度时选择当前已到达且运行时间最短的作业/进程

  **最短剩余时间优先算法（SRTN）**：每次当有进程加入就绪队列改变时就需要调度，如果到达的新进程剩余时间比当前进程剩余时间更短，则由新进程抢占处理机，当前运行进程重新回到就绪队列。

- 优缺点

  优点：可以获得“最少的”等待时间、平均周转时间

  缺点：不公平，对短作业有利，对长作业不利，可能产生饥饿现象

- 是否会导致饥饿

  会。如果源源不断的有短作业/进程到来，可能使长作业/进程长时间得不到服务，产生饥饿现象。如果一直得不到服务，则称为“饿死”。

**高响应比优先算法（HRRN）**

- 算法思想

  要综合考虑作业/进程的等待时间和要求服务的时间

- 算法规则

  在每次调度时先计算各个作业的响应比，选择响应比最高的作业为其服务

  响应比 =（等待时间+要求服务时间）/（要求服务时间）

- 用于作业/进程

  既可以用于作业调度，又可以用于进程调度

- 是否可抢占

  非抢占式的算法。因此只有当前运行的作业/进程主动放弃处理机时，才需要调度，才需要进行响应比

  综合考虑了等待时间和运行时间（要求服务时间）

- 优缺点

  优点：等待时间相同时，运行时间短的先执行，综合考虑了等待时间和运行时间

- 是否会导致饥饿

  不会

#### 2.3.5 调度算法（更适合交互式系统）

`更关注响应时间`

**时间片轮转调度算法（RR）**

- 算法思想

  公平的、轮流的为各个进程服务，让每个进程在一定时间间隔内都可以得到响应

- 算法规则

  按照各个进程到达就绪队列的顺序，轮流让各个进程执行一个时间片（如100ms）。若进程未在一个时间片内执行完，则剥夺处理机，将进程重新放到就绪队列队尾重新排队。

- 用于作业/进程调度

  用于进程调度（只有放入内存建立相应的进程后，才能被分配处理时间片）

- 是否可抢占

  若进程未能在时间片内运行完，将被强行剥夺处理机使用权，属于抢占式的算法。由时钟装置发出时钟中断来通知CPU时间片已到

- 优缺点

  若时间片太大，使得每一个进程可以在一个时间片内就完成，则退化为先来先服务算法，并且增大了进程响应时间，因此时间片不能太大。

  若时间片太小，进程切换过于频繁，系统会花大量的时间处理进程切换，从而导致实际用于进程执行的时间比例减小，因此时间片不能太小。

  优点：公平，响应快，适用于分时操作系统

  缺点：由于高频率的进程切换，有一定的开销；不区分任务的紧急程度

- 是否会导致饥饿

  不会

**优先级调度算法**

- 算法思想

  随着计算机的发展，特别是实时操作系统的出现，越来越多的应用场景需要根据任务的紧急程度来决定处理顺序

- 算法规则

  每个进程有各自的`优先级`，调度时选择优先级最高的进程

- 用于作业/进程调度

  既可以用于作业调度，也可以用于进程调度。甚至还会用于I/O调度中

- 是否可抢占

  ​	抢占式，非抢占式都有

- 优缺点

  优点：可以区分紧急程度、重要程度，适用于实时操作系统。可灵活的调整对各进程的偏好程度。

  缺点：若源源不断有高优先级进程到来，可能导致饥饿

- 是否会导致饥饿

  会

- 补充

  通常情况下

  - 系统进程优先级 高于 用户进程

  - 前台进程优先级 高于 后台进程

  - I/O约束型进程优先级 高于 CPU约束型进程

    操作系统更偏好I/O型进程（或I/O繁忙型进程，I/O约束型）

    与之相对应的为计算型进程（CPU约束型进程）

  - 动态优先级

    可从追求公平、提升资源利用率等角度考虑

    如果某进程在就绪队列中等待了很长时间，可以适当提升优先级

    如果某进程占用处理机运行了很长时间，可以适当降低其优先级

    如果发现一个进程频繁的进行I/O操作，可以适当提高其优先级

**多级反馈队列调度算法**

- 算法思想

  对其他调度算法的折中权衡

- 算法规则

  1. 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大

  2. 新进程到达时先进入第一级队列，按FCFS原则排队等待被分配时间片，若用完时间片进程还未结束，则进程进入下一级队列队尾

     如果此时已经是在最下级的队列，则重新放回该队列队尾

  3. 只有第k级队列为空时，才会为k+1级队头的进程分配时间片

  也可以动态的调整偏好程度，如果有I/O阻塞型的任务，可以将进程轮转完接着放回原队列，保持高优先级

- 用于进程调度

- 是否可抢占

  抢占式算法。在k级队列的进程运行过程中，若更上级的队列（1~k-1）中进入了一个新进程，由于新进程处于优先级更高的队列中，因此新进程会抢占处理机，原来运行的进程放回到k级队列队尾。

- 优缺点

  优点：结合了FCFS、SPF、RR等调度算法的优点

  缺点：如果有源源不断的有短进程到来的话，已经被降到低级的进程可能会饥饿

- 是否会发生饥饿

  会

### 2.4 进程同步和进程互斥

#### 2.4.1 进程同步和进程互斥

**进程同步**

根据进程那节课中，我们说明了进程的异步性，也就是说进程是走走停停，以不可预知的速度向前推进。

但在进程通信中的管道通信中，读进程一定要在写进程之后

读进程与写进程并发的运行，由于并发必然导致异步性，因此这两个进程的操作顺序是不确定的。

如何解决这种异步问题，就是进程同步所要讨论的问题。

同步也称直接制约关系，它是指为完成某种任务而建立两个或多个进程，这些进程因为需要在某些位置上协调他们的工作次序而产生的制约关系。

进程间的制约关系就是源于它们之间的相互合作。

**进程互斥**

进程的并发需要共享的支持。各个并发执行的进程不可避免的需要共享一些资源。

- 互斥共享方式
- 同时共享方式

把一个时间段内只允许一个进程使用的资源称为临界资源。许多物理设备（摄像头、打印机等）都属于临界资源。

对临界资源的访问，必须互斥的进行。互斥，亦称间接制约关系。

**进程互斥**指当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束，释放该资源之后，另一个进程才能去访问该临界资源。

**对临界资源的互斥访问分为四个部分**

```c
do {
    entry section;	//进入区（上锁）
    criticall section;	//临界区（访问临界资源的代码）
    exit section;	//退出区（解锁）
    remainder section;	//做其他处理
} while (true);
```

为了同时保证互斥访问和系统性能，遵循以下原则

- 空闲让进，临界区空闲，可允许一个请求立即进入临界区
- 忙则等待，当已有进程进入临界区时，其他进程必须等待
- 有限等待，对请求访问的进程，应保证能在有限时间内进入临界区（保证不会饥饿）
- 让权等待，当进程不能进入临界区时，应立即释放处理机，防止进程忙等待。

#### 2.4.2 进程互斥的软件实现方法

**单标志法**

- 算法思想

  两个进程在访问完临界区后会把使用临界区的权限转交给另一个进程。也就是说每个进程进入临界区的权限只能被另一个进程赋予

- 算法实现

  通过一个标志位记录允许进入临界区的进程号；

  只有该进程号可以进入临界区，其余进程均陷入循环等待状态

  当该进程使用完临界区，再修改进程号为另一个等待中的进程号

- 算法bug

  如果此时允许进入临界区的进程是P~0~，而P~0~一直不访问临界区，那么虽然此时临界区空闲，但是并不允许P~1~访问

  因此，单标志法存在的主要问题是：违背“空闲让进”原则

**双标志先检查法**

- 算法思想

  设置一个布尔型数组flag[]，数组中各个元素用来标记各进程想进入临界区的意愿，比如"flag[0] = true"意味着0号进程P~0~现在想进入临界区。

  每个进程在进入临界区之前先检查当前有没有别的进程想进入临界区，如果没有，则把自身的标志flag[i]设为true，之后开始访问临界区。

  ```c
  bool flag[2];
  flag[0] = false;
  flag[1] = false;
  ```

  ```c
  while(flag[1]);
  flag[0] = true;
  访问临界区；
  flag[0] = false;
  ```

  ```c
  while(flag[0]);
  flag[1] = true;
  访问临界区；
  flag[1] = false;
  ```

- 算法bug

  由于进程间的异步性，很可能导致两个进程的标志位均为true，也就是两个进程同时访问临界区资源。

  因此，双标志先检查法的主要问题是：违反“忙则等待”原则

**双标志后检查法**

- 算法思想

  双标志先检查法的改版。前一个算法的问题是先“检查”后“上锁”，但是这两个操作又无法一气呵成，因此导致了两个进程同时进入临界区的问题。因此，人们又想到先“上锁”后“检查”的方法，来避免上述问题。
  ```c
  bool flag[2];
  flag[0] = false;
  flag[1] = false;
  ```

  ```c
  flag[0] = true;
  while(flag[1]);
  访问临界区；
  flag[0] = false;
  ```

  ```c
  flag[1] = true;
  while(flag[0]);
  访问临界区；
  flag[1] = false;
  ```

- 算法bug

  可能导致两个进程都没法到达临界区

  双标志后检查法虽然解决了“忙则等待”问题，但是违背了“空闲让进”和“有限等待”原则，会导致饥饿现象。

**Peterson算法**

- 算法思想

  如果双方都争着想进入临界区，可以让进程尝试“孔龙让梨”，主动让对方使用临界区

  ```c
  bool flag[2];
  flag[0] = false;
  flag[1] = false;
  int turn = 0;
  ```

    ```c
  flag[0] = true;
  turn = 1;
  while(flag[1] && turn == 1);
  访问临界区；
  flag[0] = false;
    ```

    ```c
  flag[1] = true;
  turn = 0;
  while(flag[0] && turn == 0);
  访问临界区；
  flag[1] = false;
    ```

- 优点

  解决了进程互斥问题

  遵循了空闲让进、忙则等待、有限等待三个原则，但是未遵循让权等待原则。

#### 2.4.3 进程互斥的硬件实现方法

**中断屏蔽方法**

利用开/关中断指令实现（与原语实现思想相同，即在某进程开始访问临界区到结束访问为止都不允许被中断，也就不能发生进程切换，因此也不可能发生两个同时访问临界区的情况）

- 关中断：不允许当前进程被中断，也必然不会发生进程切换

- 临界区

- 开中断：直到当前进程访问完临界区，再执行打开中断指令，才有可能有别的进程上处理机并访问临界区

优点：简单、高效

缺点：不适用于多处理机；只适用于操作系统内核进程，不适用于用户进程（因为开/关中断指令只能运行在内核态）

**TestAndSet指令**

TSL是用硬件实现的，执行的过程不允许被中断，只能一气呵成

相比软件实现方法，TSL指令把“上锁和检查”操作用硬件的方式变成了一气呵成的原子操作

优点：实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞；适用于多处理机环境

缺点：不满足”让权等待“的原则

**Swap指令**

用硬件实现，执行的过程不允许被中断，只能一气呵成

与TSL优缺点一样

#### 2.4.4 信号量机制

用户进程可以通过使用操作系统提供的一对原语对信号量进行操作，从而很方便的实现了进程互斥、进程同步。

**信号量**

就是一个变量（可以是一个整数，也可以是更复杂的记录型变量），可以用一个信号量来表示系统中某种资源的数量，比如：系统中只有一台打印机，就可以设置一个初值为1的信号量。

**原语**

是一段特殊的程序段，其执行只能一气呵成，不可被中断。原语是由开/关中断指令实现的。

软件解决方案的主要问题是，进入区的各种操作不能一气呵成，因此如果能把进入区、退出区的操作都用原语实现，使这些操作能一气呵成就能避免问题。

**一对原语**

wait(S)和signal(S)原语，可以把原语理解为我们自己写的函数，函数名分别为wait和signal，括号里的信号量S其实就是函数调用时传入的参数

wait和signal原语常简称为P,V操作。因此时常将wait(S)和signal(S)两个操作分别写为P(S),V(S)。

**信号量机制**

- 整型信号量

  用一个整数型的变量作为信号量，用来表示系统中某种资源的数量。

  与普通整型变量不同的是：对信号量的操作只有三种：初始化，P操作，V操作

  eg. 某计算机系统有一台打印机

```c
int S = 1; //初始化操作

void wait (int S) {		//进入区
	while (S <= 0); 	//如果资源不够，就一直循环等待（可能发生忙等）
	S = S - 1;			//如果资源够，就占用一个资源
}

void signal (int S) {	//退出区
	S = S + 1;			//使用完资源后，在退出区释放资源
}
```

```c
进程P0
wait(S);		//进入区，申请资源
使用打印机资源；   //临界区，访问资源
signal(S);		//退出区，释放资源
```

​	如果某一进程没有请求资源时，发现该资源数量不够(S <= 0)，则进入了循环等待状态 while( S <= 0)

​	某一进程使用资源就会使信号量减1，代表使用了一个资源，当使用完打印资源，要将资源返还，执行signal函数，另资源数加1。

​	**这其实和双标志先检查是一个意思，区别就在于使用了系统为我们提供的原语，可以保证不受进程异步的影响，检查和上锁操作一气呵成。**

​	**存在的问题：** **不满足让权等待**，会发生忙等。

- ==记录型信号量==

  整型信号量存在忙等的问题。因此人们提出了记录型信号量，即用记录型数据结构表示的信号量

  ```c
  可以使用记录型信号量实现系统资源的申请和释放//记录信号量的定义
  typedef struct {
  	int value;				//剩余资源数
  	struct process *L;		//等待队列
  } semaphore;
  ```

  ```c
  //使用资源调用wait 原语申请
  void wait(semaphore S) {
  	S.value--;
  	if (S.value < 0) {
  		block(S.L);
  	}
  }
  ```

  ```c
  //进程使用资源后，通过signal原语释放
  void signal(semaphore S) {
  	S.value++;
  	if (S.value <= 0) { //只有资源不够用的时候，S.value才小于等于0
  		wakeup(S.L);
  	}
  }
  ```

  > block原语
  >
  > 使用block原语使进程从运行态到阻塞态，并把该进程挂到信号量S的等待（阻塞）队列中
  >
  > wakeup原语
  >
  > 释放资源后，若还有别的进程在等待这种资源，则使用wakeup原语唤醒等待队列中的一个进程，该进程从阻塞态变为就绪态

  可以使用记录型信号量实现系统资源的申请和释放

#### 2.4.5 用信号量机制实现进程互斥、同步、前驱关系

**信号量机制实现进程互斥**

`互斥问题：信号量初值为1`

1. 分析并发进程的关键活动，划分临界区（如：对临界资源打印机的访问就应放在临界区）
2. 设置互斥信号量mutex，初值为1（可以看作是一种数量只有1的资源）
3. 在临界区之前执行    P（mutex）
4. 在临界区之后执行    V（mutex）

**信号量机制实现进程同步**

==前V后P==

`同步问题：信号量初值为0`

进程同步：要让各并发进程按要求有序的推进，让本来异步并发的进程相互配合，有序推进。

1. 分析什么地方需要实现“同步关系”，即必须保证“一前一后”执行的两个操作
2. 设置同步信号量S，初始为0
3. 在“前操作”之后执行 V(S)
4. 在“后操作”之前执行 P(S)

eg. 保证代码4在代码2之后执行

```c
semaphore S = 0;	//初始化同步信号量，初始值为0
```

```c
P1() {
	代码1；
	代码2；
	V(S);
	代码3;
}
```

```
P2() {
	P(S);
	代码4；
	代码5；
	代码6；
}
```

只有P1中在代码2运行完之后，执行V(s)释放资源。否则如果先进入P2执行P(S)，由于S=0，会将该进程加入到阻塞队列中，直到代码2执行完之后执行了V(S)，相当于释放了资源，这时才能唤醒阻塞队列中的P2进程。

**信号量机制实现进程的前驱关系**

`更复杂的同步问题`

多个进程间需要按一定的顺序有序推进

要为每一对前驱关系都是一个进程同步问题（需要保证一前一后的操作）

1. 为每对前驱关系设置一个同步变量
2. 在前操作之后对相应的同步变量执行V操作
3. 在后操作之前对相应的同步变量执行P操作

**信号量机制对一类资源的申请和释放**

eg. 打印机资源（信号量为资源的数量）

#### 2.4.6 生产者-消费者问题

系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓存区，消费者进程每次从缓存区取出一个产品并使用。（这里的产品理解为某种数据）

生产者、消费者共享一个初始为空，大小为n的缓存区。

只有缓存区没满时，生产者才能把产品放入缓存区，否则必须等待。

只要缓存区不空时，消费者才能从中取出产品，否则必须等待。

缓冲区是临界资源，各进程必须互斥地访问。（防止缓存区资源覆盖）

PV操作题目分析步骤：

1. **关系分析**。找出题目中描述的各个进程，分析它们之间的同步互斥关系。

2. **整理思路**。根据各进程的操作流程确定P、V操作的大致顺序。

   生产者每次`消耗（P）`一个空闲缓冲区，并生产（V）一个产品。消耗者每次要消耗（P）一个产品，并`释放(V)`一个空闲缓冲区。

   往缓冲区放入/取走产品需要互斥。

3. **设置信号量**。设置需要的信号量，并根据题目条件确定信号量的初值。

```c
semaphore mutex = 1;	//互斥信号量，实现对缓冲区的互斥访问
semaphore empty = n;	//同步信号量，表示空闲缓冲区的数量
semaphore full = 0;		//同步信号量，表示产品的数量，也即非空缓冲区的数量
```

```c
producer () {
	while(1) {
		生产一个产品；
		P(empty); //消耗一个空闲缓存区
		P(mutex); //上锁
		把产品放入缓存区；
		V(mutex); //解锁
		V(full);  //释放一个产品
	}
}
```

```c
consumer () {
    while(1) {
        P(full);	//消耗一个产品
        P(mutex);
        从缓冲区取出一个产品；
        V(mutex);
        V(empty);	//释放了一个空闲缓存区
        使用产品；
    }
}
```

> - 实现互斥是在同一进程中进行一对PV操作
>
> - 实现两进程的同步关系，是在其中一个进程中执行P，另一个进程中执行V
>
> - 实现互斥的P操作一定要在实现同步的P操作之后，否则会引起死锁现象
> - 生产一个产品和使用产品不放到PV操作之间，减少使用临界区的时间，这样其他想要访问临界区的进程不容易发生阻塞，提高并发度

----

**多生产者多消费者问题**

#### 2.4.7 **吸烟者问题**

```c
semaphore offer1 = 0;	//桌上组合1的数量
semaphore offer2 = 0;	//桌上组合2的数量
semaphore offer3 = 0;	//桌上组合3的数量
semaphore finish = 0;	//抽烟是否完成
int i = 1;				//用于实现“三个抽烟者轮流抽烟”
```

```c
privider () {
	while (1) {
        if (i == 0) {
			将组合1放到桌上；
            V(offer1);
        } else if (i == 1) {
            将组合2放到桌上；
            V(offer2);
        } else if (i == 2) {
            将组合3放到桌上；
            V(offer3);
        }
        i = (i + 1) % 3; //轮流
        P(finish);
	}
}
```

```c
smoker1 () {
	while (1) {
		P(offer1);
		从桌上拿走组合1；
		卷烟；抽掉；
		V(finish);
	}
}
```

> smoker2,smoker2与smoker1类似

#### 2.4.8 读写进程问题

**要求**

- 允许多个读者可以同时对文件执行读操作
- 只允许一个写者向文件中写信息 （互斥）
- 任一写者在完成写操作之前不允许其他读者或写者工作 
- 写者执行写操作前，应让已有的读者和写者全部退出

**问题分析**

1. 关系分析

   找出题目中描述的各个进程，分析它们之间的同步、互斥关系。

   两类进程：写进程、读进程

   互斥关系：写进程-写进程、写进程-读进程、读进程与读进程之间不存在互斥问题

2. 整理思路

   根据各进程的操作流程确定P、V操作的大致顺序

3. 设置信号量

   设置需要的信号量，并根据题目条件确定信号量初值。（互斥信号量初值一般为1，同步信号量初值要看对应资源的初始值是多少）

**关键问题：**如何处理读写进程互斥，读进程之间不互斥的问题

**使用读写锁**

读写锁又称共享-独占锁，对于读共享，写独占。

- 当读写锁加了写锁时，其他线程对该锁加读锁或者写锁都会阻塞；
- 当读写锁加了读锁时，其他线程对写锁阻塞，读锁成功；

```c
pthread_rwlock_t rwlock;

pthread_rwlock_rdlock(&rwlock);
读
pthread_rwlock_unlock(&rwlock);

pthread_rwlock_wrlock(&rwlock);
写
pthread_rwlock_unlock(&rwlock);

pthread_rwlock_destory(&rwlock);
```

#### 2.4.9 哲学家进餐问题

1. 关系分析

   系统中有5个哲学家进程，5位哲学家与左右邻居对其中间筷子的访问是互斥的。

2. 整理思路

   这个问题只有互斥关系，但与之前的问题不同的是，每个哲学家进程需要同时持有两个临界资源才能开始吃饭。

   如何避免临界资源分配不当造成的死锁现象，是哲学家问题的精髓。

3. 信号量设置

   定义互斥信号量数组chopstick[5] = {1,1,1,1,1}用于实现对5个筷子的互斥访问。并对哲学家按0～4进行编号，哲学家i左边的筷子编号为i，右边的筷子编号为(i+1)%5

```c
semaphore chopstick[5] = {1, 1, 1, 1, 1};
semaphore mutex = 1;
Pi () {
	while (1) {
		P(mutex);
		P(chopstick[i]);
		P(chopstick[(i+1)%5]);
		V(mutex);
		吃饭...
		V(chopstick[i]);
		V(chopstick[(i+1)%5]);
		思考...
	}
}
```

**解决方法**

- 最多只允许四个哲学家进餐，最后肯定有一个筷子剩余，那么一定会有一个哲学家可以吃饭
- 要求奇数号哲学家先拿左边的筷子，然后再拿右边的筷子，而偶数号哲学家正好相反

#### 2.4.10 管程

管程是一种特殊的软件模块，由这些部分组成：

- 局部于管程的共享数据结构说明
- 对该数据结构进行操作的一组过程（函数）
- 对局部于管程的共享数据设置初始值的语句
- 管程有一个名字

**管程的基本特征**

1. 局部于管程的数据只能被局部于管程的过程所访问
2. 一个进程只有通过调用管程内的过程才能进入管程访问共享数据
3. 每次仅允许一个进程在管程内执行某个内部过程

### 2.5 死锁

#### 2.5.1 死锁的概念

**死锁：**各进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。（至少两个进程）

**饥饿：**进程长时间得不到想要的资源，某进程无法向前推进的现象。(单进程)

**死循环：**某进程执行过程中一直跳不出某个循环的现象。（可以是运行态）

**死锁产生的必要条件**

- 互斥条件

  只有对必须互斥使用的资源的争抢才会导致死锁。

- 不可剥夺条件

  进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。

- 请求和保持条件

  进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。

- 循环等待条件

  存在一种进程的循环等待链

  `循环等待未必死锁，死锁一定有循环等待`

**什么时候发生死锁**

- 对系统资源的竞争
- 进程推进顺序非法
- 信号量的使用不当

**总之，对不可剥夺资源的不合理分配，可能导致死锁**

**死锁的处理策略**

- 死锁预防 （预防火灾）

  破环死锁出现的条件 

- 死锁避免 （检测到煤气超标时，自动切断电源）

  检测每个资源请求，如果造成死锁就拒绝

- 死锁检测+修复 （发现火灾时，立刻拿起灭火器）

  检测到死锁出现时，让一些进程回滚，让出资源

- 死锁忽略 （在太阳上可以对火灾全然不顾）

  就好像没有出现死锁一样

**死锁忽略的引出：**

- 死锁预防：引入太多不合理因素，在进程执行前，一次性申请所有需要的资源，资源利用率低，编程困难
- 死锁避免：每次申请都执行银行家算法O（mn^2^），效率太低
- 死锁检测+恢复：恢复很不容易，进程造成的改变很难恢复
- 死锁忽略：死锁出现不是确定的，又可以用重启动来处理死锁

#### 2.5.2 预防死锁

**破环死锁产生的四个条件**

- 破坏互斥条件

  互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁

  采用SPOOLing技术，把互斥使用的资源改造为允许共享使用

  缺点：并不是所有的资源都可以改造成可共享使用的资源。并且为了系统安全，很多地方还必须保护这种互斥性。因此，很多时候都无法破坏互斥条件。

- 破坏不剥夺条件（放弃+抢夺）

  不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。

  - 方案一：当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待以后需要时再重新申请。也就是说，即使某些资源尚未使用完，也需要主动释放，从而破坏了不可剥夺条件。
  - 方案二：当某个进程需要的资源被其他进程占有的时候，可以由操作系统协助，将想要的资源强行剥夺。

  缺点：实现比较复杂，释放已获得的资源可能造成前一阶段工作的失效。

  反复地申请和释放资源会增加系统的开销，降低系统吞吐量。

- 破坏请求和保持条件

  请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源由被其他进程占有，此时请求进程被堵塞，但又对自己已有的进程保持不放。

  可以采用静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不让它投入运行。一旦投入运行后，这些资源就一直归它所有，该进程就不会再请求别的任何资源。

  缺点：资源利用率低，可能导致某些进程饥饿

- 破坏循环等待条件

  循环等待条件：存在一种进程的资源等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。

  可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（即编号相同的资源）一次申请完。

  缺点：不方便增加新的设备；进程实际使用的资源顺序可能和编号递增顺序不一致，会导致资源浪费

#### 2.5.3 避免死锁

**安全序列**

指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态。安全序列可能有多个。

如果分配了资源之后，系统找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后可能所有进程都无法顺利的执行下去。

> 每次用资源总数与各进程所需资源数进行对比，如果满足需求，则将该进程加入序列，并将该进程的资源数加到资源总数中，若到最后资源总数可以满足所有进程需求，则这是一组安全序列。

**如果系统处于安全状态，就一定不会发生死锁。如果系统进入不安全状态，就可能发生死锁。**

因此可以在分配资源之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求。这也是”银行家算法“的核心思想。

**核心思想**

==在进程提出资源申请时，先预判此次分配是否会导致系统进入不安全状态。如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待。==

**步骤**

- 检查此次申请是否超过了之前声明的最大需求数
- 检查此时系统剩余的可用资源是否满足这次请求
- 试探着分配，更改各数据结构
- 用安全性算法检查此次分配是否会导致系统进入不安全状态

检查当前剩余可用资源是否满足某个进程的最大需求，如果可以，就把进程加入安全序列，并把该进程持有的资源全部回收。

不断重复上述过程，看最终是否能让所有的进程都加入安全序列。

#### 2.5.4 检测和解除

**死锁检测算法：**用于检测系统状态，以确定系统中是否发生了死锁

**死锁解除算法：**当认定系统已经发生了死锁，利用该算法可将系统从死锁状态解脱出来

**死锁检测**

依次消除与不阻塞进程相连的边，直到无边可消

**死锁解除**

并不是系统中所有的进程都是死锁状态，用死锁检测算法化简资源分配图，还连着边的那些进程就是死锁进程

- 资源剥夺法

  挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但是防止被挂起的进程长时间得不到资源而饥饿。

- 撤销进程法

  强制撤销部分、甚至全部死锁的进程，并剥夺这些进程的资源。这种方式的优点是实现简单，但所付出的代价可能会很大。因为有些进程可能已经运行了很长时间，已经接近结束了，一旦被终止可谓功亏一篑。

- 进程回退法

  让一个或多个死锁进程回退到足以避免死锁的地步。这就要记录进程的历史消息，设置到原点。

## 3. 内存管理

### 3.1 内存基本概念

**内存：**内存是用于存放数据的硬件，程序执行前先放到内存中才能被CPU处理。

**逻辑地址和物理地址**

编译时产生的指令只关心“相对地址”，实际放入内存中时再想办法根据起始位置得到“绝对地址”。

> eg. 编译时只需要确定变量x存放的相对地址是100（也就是相对于进程在内存中的起始地址而言的地址）。CPU想要找到x在内存中的实际存放位置，只需用进程的起始地址+100即可。

相对地址又称逻辑地址，绝对地址又称物理地址。

**从写程序到程序运行**

- 编辑源代码

- 编译为目标模块（每个模块有自己的逻辑地址）

  由编译程序将用户源代码编译成若干个目标模块（编译就是把高级语言翻译为机器语言）

- 链接（将各模块的逻辑地址汇总为完整的逻辑地址）

  由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块

- 装入（装载）（将逻辑地址转换为物理地址存入内存中）

  由装入程序将装入模块装入内存运行

**装入模块装入内存**（逻辑地址-->物理地址）

装入的三种方式：用3种不同的方法完成逻辑地址到物理地址的转换

1. 绝对装入（编译时）

   在编译时，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码，装入程序按照装入模块中的地址，将程序和数据装入内存。

2. 静态重定位（装入时）

   编译、链接后的装入模块的地址都是从0开始的，指令中使用的地址、数据存放的地址都是相对于起始而言的逻辑地址。可根据内存的当前使用情况，将装入模块装入到内存的适当位置。装入时对地址进行重定位，将逻辑地址变换为物理地址（地址变换是在装入时一次完成的）。

   特点：一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。作业一旦进入内存后，在运行期间就不能再移动，也不能再申请内存空间。

3. **动态重定位（运行时）**

   编译、链接后的装入模块的地址都是从0开始的，装入程序把模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要执行时才进行。因此装入内存后的所有地址依然是逻辑地址。这种方式需要一个重定位寄存器的支持。

   重定位寄存器中存放的是起始位置

   采用动态重定位时允许程序在内存中发生移动。

   优点：可将程序分配到不连续的存储区中；在程序运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大的多的地址空间。

**链接的三种方式**

1. 静态链接（装入前链接）

   在程序运行之前，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开。

2. 装入时动态链接（边装入边链接）

   将各目标模块装入内存时，边装入边链接的链接方式。

3. 运行时动态链接（运行时链接）

   在程序执行中需要该目标模块时，才对它进行链接。其优点是便于修改和更新，便于实现对目标模块的共享。

### 3.2 内存管理基础

#### 3.2.1 内存管理概念

**内存管理3个问题**

1. 操作系统要怎么记录哪些内存区域已经被分配出去了，哪些又还在空闲
2. 很多位置可以放，那应该放在哪里
3. 当进程运行结束之后，如何将进程占用的内存空间回收

**内存管理在做什么**

1. 操作系统负责内存的分配与回收

2. 操作系统提供某种技术从逻辑上对内存空间进行扩充

   - 覆盖技术
   - 交换技术
   - 虚拟存储技术

3. 操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换

4. 操作系统需要提供内存保护功能，保证各进程在自己存储空间内运行，互不干扰

   内存保护的两种方法：

   - 法一：在CPU中设置一对上下限寄存器，存放进程的上下限地址。进程的指令要访问某个地址时，CPU检查是否越界
   - 法二：采用重定位寄存器和界地址寄存器进行越界检查。重定位寄存器中存放的是进程的起始物理地址。界地址寄存器存放的是进程的最大逻辑地址。

#### 3.2.2 覆盖与交换

**覆盖**

**覆盖技术的思想：**将程序分为多个段（多个模块）。**常用的常驻内存，不常用的段在需要时调入内存。**

内存中分为一个“固定区”和若干个“覆盖区”

需要常驻内存的段放在“固定区”中，调入后就不再调出（除非运行结束）

不常用的段放在“覆盖区”，需要用到时调入内存，用不到时调出内存

`按照自身逻辑结构，让那些不可能同时被访问的程序段共享同一个覆盖区`

缺点：必须由程序员声明覆盖结构，对用户不透明，增加编程负担

**交换**

**交换技术的核心思想：**内存空间紧张时，系统将内存中的某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存（进程在内存与磁盘间动态调度）。

暂时换出外存等待的进程状态为`挂起状态`（挂起态，suspend）

挂起态又可以进一步细分为就绪挂起、阻塞挂起两种状态

换出的进程放在磁盘的对换区（磁盘分为文件区和对换区，对换区的I/O速度比文件区快）

#### 3.2.3 连续分配管理方式

内存的分配与回收

**连续分配：指为用户进程分配的必须是一个连续的内存空间**

**单一连续分配方式**

内存被分为系统区和用户区，系统区通常位于内存的低地址部分，用于存放操作系统相关数据；用户区用于存放用户进程相关数据。

内存中只能有一道用户程序，用户程序独占整个用户区空间

优点：实现简单，无外部碎片

缺点：只能用于单用户、单任务的操作系统中；有内部碎片；存储利用率极低。

**固定分区分配**

**将整个用户空间划分为若干个固定大小的分区，在每个分区中只装入一道作业，**这样就形成了最早的、最简单的一种可运行多道程序的管理方式。

- 分区大小相等

  缺乏灵活性，但是很适用于用一台计算机控制多个相同对象的场合

- 分区大小不等

  增加了灵活性，可以满足不同大小的进程需求。

操作系统需要建立一个数据结构--分区说明表，来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小、起始地址、状态（是否已分配）。

优点：实现简单，无外部碎片

缺点：当用户程序太大时，可能所有的分区都不能满足需求，此时不得不用覆盖技术解决，降低性能；会产生内部碎片，内存利用率低。

**动态分区分配**（可变分区分配）

这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统分区的大小和数目是可变的。

1. 系统用什么样的数据结构记录内存的使用情况

   - 空闲分区表
   - 空闲分区链

2. 当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配

   采用动态分区分配算法

3. 如何进行分区的分配与回收

   - 回收区后面有一个相邻的空闲分区

     两个相邻的空闲分区合并为一个

   - 回收区前面有一个相邻的空闲分区

   - 回收区前后有一个相邻的空闲分区

     三个相邻的空闲分区合并为一个

   - 回收区前后都没有相邻的空闲分区

     增加一个空闲分区的表项

动态分区分配没有内部碎片，但是有外部碎片

内部碎片：分配给某进程的内存区域中，如果某些部分没有用上

外部碎片：是指内存中的某些空闲分区由于太小而难以利用

如果内存中空闲空间的总和本来可以满足某进程的需求，但由于进程需要的是一块连续的内存空间，因此这些“碎片”不能满足进程的需求。

可以通过紧凑技术解决外部碎片。

#### 3.2.4 动态分区分配算法

在动态分区分配方式中，当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配？

**首次适应算法**

- 算法思想：每次从低地址开始查找，**找到第一个满足大小的空闲分区**
- 如何实现：空闲分区以地址递增的次序排列。每次分配内存时动态查找空闲分区链，找到大小能满足要求的第一个空闲分区。

**邻近适应算法**

- 算法思想：每次都从链头开始查找。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
- 空闲分区以地址递增的顺序排列（可排成一个循环链表），每次分配内存时从上次查找结束的位置开始查找空闲分区链（表），找到大小能满足要求的第一个空闲分区。

**最佳适应算法**

- 算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续大片空间，可以尽可能多地留下大片的空闲区，优先使用更小的空闲区。
- 如何实现：空闲分区链按容量递增次序链接。每次分配内存时顺序查找空闲分区链，找到大小能满足要求的第一个空闲分区。

**最坏（大）适应算法**

- 算法思想：为了解决最佳适应算法的问题：留下太多难以利用的小碎片，可以在分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。
- 如何实现：空闲分区按容量递减顺序链接。每次分配时顺序查找空闲分区链，找到大小能满足要求的第一个空闲分区。
- 缺点：后来的大进程无处安放

### 3.3 内存分页

#### 3.3.1 基本分页存储管理的概念

`非连续分配管理方式`

**非连续分配：为用户进程分配的可以是一些分散的内存空间**

**基本分页存储管理的思想：把内存分为一个个相等的小分区，再按照分区大小把进程拆分成一个个小部分**

- 将内存空间分为一个个大小相等的分区（比如每个分区4KB），每个分区就是一个“页框”，或称“页帧”、“内存块”、“物理块”。

每个页框有一个编号，即“页框号”（从0开始）

- 将用户进程的地址空间也分为与页框大小相等的一个个区域，称为“页”或“页面”。每个页面也有一个编号，即“页号”，页号也是从0开始。

`页框不能设置太大，否则可能产生过大的内部碎片`

- 操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应关系。各个页面不必连续存放，也不必按先后顺序来，不必相邻。

**如何实现地址的转换**

1. 要算出逻辑地址对应的页号

2. 要知道该页号对应的页面在内存中的起始地址

   操作系统为**每个进程**建立了**一张页表**

   - 一个进程对应一张页表
   - 进程的每一页对应一个页表项
   - 每个页表项由页号和块号组成
   - 页表记录进程页面和实际存放的内存块之间的对应关系（根据块号就可以知道该页对应的页框在内存中的起始地址 M号内存块的起始地址就是M*内存块大小）
   - 每个页表项的长度是相同的，但是页号是“隐含”的

3. 要算出逻辑地址在页面内的“偏移地址”

4. 物理地址 = 页面地址 + 页内偏移量

**如何计算**

- 手动计算

页号 = 逻辑地址 / 页面长度 （取除法的整数部分）

页内偏移量 = 逻辑地址 % 页面长度 （取除法的余数部分）

页号在页面内的起始位置：操作系统需要使用某种数据结构记录进程各个页面的起始位置

- 计算机计算

  为了方便计算页号，页内偏移量，页面大小一般设为2的整数幂

  如果每个页面大小为2^k^B，用二进制数表示逻辑地址，则末尾K位即为页内偏移量，其余部分就是页号

  如果有K位表示“页内偏移量”，则说明系统中一个页面的大小是2^K^个内存单元

  如果有M位表示“页号”，则说明在该系统中，一个进程最多允许有2^M^个页面

#### 3.3.2 基本地址变换机构

用于实现逻辑地址到物理地址转换的一组硬件机构

基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。

通常会在系统中设置一个==页表寄存器（PTR）==，存放页表在内存中的起始地址F和页表长度M。

进程未执行时，页表的始址和页表长度放在进程控制块（PCB）中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。

设页面大小为L，逻辑地址A到物理地址E的变换过程如下：

1. 计算页号P和页内偏移量W

2. 比较页号P和页表长度M，若P>=M，则产生越界中断，否则继续执行。

3. 页表中页号P对应的==页表项地址=页表起始地址F+页号P*页表项长度==，取出该页表项内容b，即为内存块号。

   页表长度：指的是这个页表中共有几个页表项，即总共有几个页；

   页表项长度：指的是每个页表项占多大的存储空间；

   页面大小：指的是一个页面占多大的存储空间；

4. 计算物理地址E=b*L+W，用得到的物理地址区访问内存。

**页式管理中地址是一维的，也就是说只需要告诉CPU一个信息，也就是逻辑地址，CPU就能为我们找到物理地址**

**整个过程总共需要访问两次内存：一次是查页表，另一次是访问目标内存单元**

#### 3.3.3 具有快表的地址变换机构

是基本地址变换机构的改进版

**快表**

又称联想寄存器（TLB），是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程。

与此对应，内存中的页表常称为慢表。

**引入快表后，地址的变换过程**

1. CPU 会给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较。
2. 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后访问该物理地址对应的内存单元。因此，若快表命中，则访问某个逻辑地址仅需要一次访问即可。

3. 如果没有找到匹配的页号，则需要访问内存中的页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后访问该物理地址对应的内存单元，这时需要两次访存。（在找到页表项后，应同时将其存入快表，以便再次访问）

> 命中：一次访存（通过快表直接访存）
>
> 未命中：两次访存（慢表，内存），一次存储（存储至快表）

**引入快表机制后，访问一个逻辑地址的速度快多了**

#### 3.3.4 两级页表

**单级页表存在的两个问题**

- 问题1：页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框

  > 离散式存储的引入就是为了解决连续存储造成的内存利用率低的问题，但是这里当页表很大又要对它进行连续存储（连续占用很多个页框）的话，显然是违背了离散式存储的思想
  >
  > 所以我们应对页表页采用离散式存储的方式，这时我们可以将页表进行拆分分组，使得页面大小的页表项为一组，这就需要一个页目录表来记录页表的位置，这就是两级页表

- 问题2：没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面

  虚拟存储技术

**解决方法**

可将长长的页表进行分组，使每个内存块刚好可以放入一个分组

另外需要为离散分配的页表再建立一张页表，称为页目录表，或称外层页表，或称顶层页表

**步骤**

1. 按照地址结构将逻辑地址拆分成三部分
2. 从PCB中读出页目录表始址，再根据一级页号查页目录表，找到下一级页表在内存中的存放位置
3. 根据二级页号查表，找到最终想访问的内存块号
4. 结合页内偏移量得到物理地址

> 若采用多级页表机制，则各级页表的大小不能超过一个页面
>
> 两级页表的访问次数分析（假设没有快表机构）
>
> - 第一次访存：访问内存中的页目录表
> - 第二次访存：访问内存中的二级页表
> - 第三次访存：访问目标中的内存单元
>
> n级页表需要访存n+1次

#### 3.3.5 基本分段存储管理方式

**分段**

- 进程的地址空间：**按照程序自身的逻辑关系划分为若干个段**，每个段都有一个段名，每段从0开始编址

- 内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻

- 优点：由于是按逻辑功能划分段，所以用户编程更方便，程序的可读性更高

- 分段系统的逻辑地址由段号（段名）和段内地址（段内偏移量）所组成

> 段号的位数决定了每个进程最多可以分几个段
>
> 段内地址位数决定了每个段最大长度是多少

**段表**

程序分多个段，各段离散地装入内存，为了保证程序能够正常运行，就必须能从物理内存中找到各个逻辑段的存放位置。为此，需为每个进程建立一张段映射表，简称段表。

1. 每个段对应一个段表项，其中记录了该段在内存中的起始位置（又称“基址”）和段的长度。
2. 各个段表项的长度是相同的（6B）

**段表寄存器：**存放段表始址、段表长度

**分段与分页**

- 页是信息的物理单位。分页的主要目的是为了**实现离散分配**，**提高内存利用率**。分页仅仅是**系统管理上的需要**，完全是系统行为，对用户是不可见的。
- 段是信息的逻辑单位。分段的主要目的是**更好地满足用户需求**。一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显示的给出段名。

**页的大小固定且由系统决定。段的长度却不固定**，决定于用户编写的程序。

分页的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址。

分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址。（这是由于各个段的长度不同，所以段号必须要声明）

**分段比分页更容易实现信息的共享和保护**

#### 3.3.6 段页式管理方式

**分页、分段的优缺点分析**

|          |                             优点                             |                             缺点                             |
| -------- | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 分页管理 | 内存空间利用率高，**不会产生外部碎片**，只会有少量的页内碎片 |             不方便按照逻辑块实现信息的共享和保护             |
| 分段管理 |            很方便按照逻辑模块实现信息的共享和保护            | 如果段长过大，为其分配很大的连续空间会很不方便。另外，段式管理**会产生外部碎片** |

**分段+分页=段页式管理**

将进程按照逻辑模块分段，再将各段分页（如每个页面4kb）

再将内存空间分为大小相同的内存块/页框/页帧/物理块

**段页式管理的逻辑地址结构**

| 段页式 | 段号 | 页号 | 页内偏移量 |
| :----: | :--: | :--: | :--------: |
|  页式  |      | 页号 | 页内偏移量 |
|  段式  | 段号 |      |  段内地址  |

段号的位数决定了每个进程最多可以分几个段

页号位数决定了每个段最大有多少页

页内偏移量决定了页面大小、内存块大小是多少

段页式管理的地址结构是二维的（因为分页对用户是不可见的），即需要给出段名和段内地址

**段表、页表**

每个段对应一个段表项，每个段表项由段号、页表长度、页表存放块号（页表起始地址）组成。每个段表项长度相等，段号是隐含的。

每个页面对应一个页表项，每个页表项由页号、页面存放的内存块号组成。每个页表项长度相等，页号是隐含的。

**需要三次访存**

- 第一次访存：段表
- 第二次访存：页表
- 第三次访存：内存

#### 3.3.7 虚拟内存的基本概念

**传统存储管理方式的特征、缺点**

- 一次性：作业必须一次性全部装入内存后才能开始运行。就会造成两个问题
  - 作业很大时，不能全部装入内存，导致大作业无法运行
  - 当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降
- 驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。

**高速缓冲技术思想：**将近期会频繁访问到的数据放到更高速的存储器中，暂时用不到的数据放在更低速的存储器中。

**虚拟内存**

基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。

==在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需要的信息从外存调入内存，然后继续执行程序。==

==若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。==

在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存。

**操作系统虚拟性的体现，实际的物理内存大小没有变，只是在逻辑上进行了扩充**

> 虚拟内存最大容量是计算机的地址结构（CPU寻址范围）确定的
>
> 虚拟内存实际容量=min（内外存容量之和，CPU寻址范围）

**主要特征**

- 多次性：无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存
- 对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出
- 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量

**实现**

虚拟内存技术，允许一个作业分多次调入内存。如果采用连续分配方式，会不方便实现。因此，**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上**。

- 请求分页存储管理
  - **请求调页：在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需要的信息从外存调入内存，然后继续执行程序。**
  - **请求置换：若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。**
- 请求分段存储管理
- 请求段页式存储管理

#### 3.3.8 请求分页管理方式

请求分页存储管理与基本分页存储管理的主要区别：

- 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需要的信息从外存调入内存，然后继续执行程序。
- 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。

**页表机制**

- 与基本分页管理相比，请求分页管理中，为了实现“请求调页”，操作系统需要知道每个页面是否已经调入内存；如果还没调入，那么也需要知道该页面在外存中存放的位置。

- 当内存空间不够时，要实现“页面置换”，操作系统需要通过某些指标来决定到底换出哪个页面；

  有的页面没有被修改过，就不用再浪费时间写回外存；

  有的页面被修改过，就需要将外存中的旧数据覆盖（更新数据）；

  因此，操作系统也需要记录各个页面是否被修改的信息。

页表增加了一些字段，如下

| 页存块号 |     状态位     |                           访问字段                           |           修改位           |        外存地址        |
| :------: | :------------: | :----------------------------------------------------------: | :------------------------: | :--------------------: |
|          | 是否已调入内存 | 可记录最近被访问过几次，或记录上次访问的时间，供置换算法选出换出页面时参考 | 页面调入内存后是否被修改过 | 页面在外存中的存放位置 |

**缺页中断机构**（内中断）

**在请求分页系统中，每当要访问的页面不在内存时，便产生一个缺页中断，然后由操作系统的缺页中断处理程序处理中断。**

**此时缺页的进程阻塞，放入阻塞队列，调页完成后再将其唤醒，返回就绪队列。**

如果内存中出现空闲块，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项。

如果内存中没有空闲块，则由页面置换算法选择一个页面淘汰，若该页面在内存期间被修改过，则将其写回外存。未修改过的页面不用写回外存。

**地址变换机构**

与基本分页管理不同的是，新增步骤：

- 请求调页（查到页表项时进行判断）
- 页面置换（需要调入页面，但没有空闲内存块时进行）
- 需要修改请求页表中新增的表项

#### 3.3.9 页面置换算法

页面的换入换出需要磁盘I/O，会有较大的开销，因此好的页面置换算法应该追求更少的缺页率。

1. **最佳置换算法（OPT）**

   每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。

   注意：缺页时未必发生页面置换，若还有可用的空闲内存块，就不用发生页面置换。

   问题：最佳置换算法可以保证最低的缺页率，但实际上，只有在执行过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。

   ​			因此，最佳置换算法是无法实现的。

2. **先进先出置换算法（FIFO）**

   每次选择淘汰的页面是最早进入内存的页面

   实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可。队列的最大长度取决于系统为进程分配了多少个内存块。

   问题：Belady异常--当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。

   只有FIFO算法会产生Belady异常。另外，FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问。因此，算法性能差。

3. **最近最久未使用置换算法（LRU）**

   每次淘汰的页面是最近最久未使用的页面。

   实现方法：赋予每个页面对应的页表项中，用访问字段记录页面自上次被访问以来所经过的时间t。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面。

   问题：需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大。

4. **时钟置换算法（CLOCK）**

   是一种性能和开销比较均衡的算法，又称最近未使用（NRU）算法

   - 简单的CLOCK算法

     为每个页面设置一个`访问位`，再将内存中的页面都通过链接指针链接成一个循环队列。

     当某页被访问时，其访问位置为1。当需要淘汰一个页面时，只需检测页的访问位。
  >如果是0，将该页换出，如果是1，则将它置为1，暂不换出，继续检查下一个页面。

   - 改进的时钟置换算法
   
     条件都相同时，应优先淘汰没有修改过的页面，避免I/O操作。设置`访问位`、`修改位`。

#### 3.3.10 页面分配策略

**页面分配和置换策略**

**驻留集：**指请求分页存储管理中给进程分配的物理块的集合。

**固定分配：**操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。即，驻留集大小不变

**可变分配：**先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加和减少。即，驻留集大小可变

**局部置换：**发生缺页时只能选进程自己的物理块进行置换

**全局置换：**可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程

**抖动（颠簸）现象**

刚刚换出的页面马上又要换出内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动。产生原因是进程频繁访问的页面数目高于可用的物理块数（分配给进程的物理块不够）

**解决抖动方法**

**工作集：**指再某段时间间隔里，进程实际访问页面的集合

根据工作集的大小确定驻留集的大小，一般来说，驻留集的大小不能小于工作集的大小，否则进程运行过程中将频繁缺页

## 4. 文件管理

 ### 4.1 基本概念

#### 4.1.1 文件管理基础

文件--就是一组有意义的信息/数据集合

**文件属性**

- 文件名：由创建的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件。
- 标识符：一个系统内的各文件标识符唯一，对用户来说毫无可读性， 因此标识符只是操作系统为了区分各个文件的一种内部名称
- 类型：指明文件的类型
- 位置：文件存放的路径、在外存中的地址（操作系统使用，对用户不可见）
- 大小：指明文件大小
- 创建时间、上次修改时间文件所有者信息
- 保护信息：对文件进行保护的访问控制信息

**文件内部的数据应该怎样组织起来**

- 无结构文件（文本文件）

  由一系列二进制或字符流组成

- 有结构文件（数据库表），由一组相似的记录组成，又称“记录式文件”

  记录是一组相关数据项的集合；数据项是文件系统中最基本的数据单位

  文件夹也是一种有结构文件

**操作系统向上提供的功能**

- 创建文件：create系统调用
- 删除文件：delete
- 读文件：read
- 写文件：write
- 打开文件：open
- 关闭文件：close

**文件如何存入外存**

类似于内存分为一个个内存块，外存会分为一个个“块/磁盘块/物理块”，每个磁盘块的大小是相等的。

文件的逻辑地址可以分为（逻辑块号，块内地址），操作系统同样需要将逻辑地址转换为外存的物理地址（物理块号，块内地址）的形式。

**文件管理功能**

- 文件共享：使多个用户可以共享使用一个文件
- 文件保护：如何保证不同的用户对文件有不同的操作权限

### 4.2 文件结构

#### 4.2.1 文件的逻辑结构

逻辑结构：文件内部的数据应该是如何组织起来的。

**有结构文件**（数据库表）

由一组相似的记录组成，又称“记录式文件”

记录是一组相关数据项的集合；数据项是文件系统中最基本的数据单位（比如：姓名|学号|年龄，这就是一组记录，由若干个数据项组成）

一般来说，每条记录有一个数据项可作为关键字。根据每条记录的长度是否相等，又可分为定长记录和可变长记录两种。

**有结构文件的逻辑结构**

- 顺序文件

  文件中的记录一个接一个地**逻辑上**顺序排列，记录可以是定长的（学号）或可变长的（姓名），各个记录在物理上可以顺序存储或链式存储。

  - 顺序存储：逻辑上相邻，物理上相邻
  - 链式存储：逻辑上相邻，物理上不相邻

  也可以分为串结构与顺序结构

  - 串结构：记录之间的顺序与关键字无关
  - 顺序结构：记录之间的顺序按关键字顺序排列

- 索引文件

  建立一张索引表以加快文件检索速度，每条记录对应一个索引项。

  索引表信息连续存储，可以通过索引号快速定位文件，通过指针来访问该文件

  文件中的这些记录在物理上可以离散地存放

  `索引表本身是定长记录的顺序文件`

- 索引顺序文件

  索引文件的空间利用率低（因为索引表占的空间比较大）

  索引文件是每个记录都要对应一张索引表

  索引顺序文件是索引文件与顺序文件的结合；不过它是一组记录对应一个索引表项。

  为所有的记录分组，然后对这些组建立索引，可以更快速的定位文件。

- 多级索引顺序文件

#### 4.2.2 文件目录

目录本身就是一种有结构文件，由一条条记录组成。每条记录对应一个在该目录下的文件

**文件控制块（FCB）**

目录文件中的一条记录就是一个文件控制块（FCB）

FCB的有序集合称为文件目录，一个FCB就是一个文件目录项

FCB中包含了文件的基本信息（文件名、物理地址、逻辑地址、物理结构等），存取控制信息，使用信息

最重要，最基本的还是文件名、文件存放的物理地址

**对目录操作**

- 搜索：当用户要使用一个文件时，系统要根据文件名搜索目录，找到该文件对应的目录项。

- 创建文件：创建一个新文件，需要在其所属的目录中增加一个目标项

- 删除文件：当删除一个文件时，需要在目录中删除相应的目录项

- 显示目录：用户可以请求显示目录的内容，如显示该目录中的所有文件及相关属性
- 修改目录：某些文件属性保存在目录中，因此这些属性变化时需要修改相应的目录项

**目录结构**

- 单级目录结构

  整个系统中只有一张目录表，每个文件占一个目录项

  缺点：不允许目录重名

- 两级目录文件

  分为主文件目录和用户文件目录

  优点：可以方便的为不同用户增加一些权限，允许不同用户的文件重名

  缺点：缺乏灵活性，不能对自己的文件进行分类

- 树形目录结构

  用户要访问某个文件时要用文件路径名标识符

  优点：不同目录下的文件可以重名

  系统根据`绝对路径`一层一层地找到下一级目录。刚开始从外存读入根目录的目录表；找到目标文件目录的存放位置后，从外存读入对应的目录表；再找到目标文件的存放位置，再从外存读入对应目录表，最后找到目标文件。需要经过多次I/O操作。

  为了提高效率，可以从`相对路径`（当前目录）出发，这样只需要一次I/O操作

  优点：很方便对文件进行分类，层次结构清晰，可以有效地进行文件的管理和保护

  缺点：不便于实现文件的共享

- 无环图目录结构

  在树形目录的基础上，增加了一些指向同一节点的有向边，使整个目录成为一个有向无环图，可以方便地实现多个用户间的文件共享

  可以用不同的文件名指向同一个文件，甚至可以指向同一个目录，需要为共享结点设置一个共享计数器

**索引结点**（FCB的改进）

我们在查找文件时，通常最关心的只有文件名，所以可以把其他的一些信息存放到索引结点中，目录表中只存放文件名和指向索引结点的指针。

**大大提升了文件的检索速度**

#### 4.2.3 文件的物理结构

文件的逻辑地址空间也被分为了一个一个的文件块；

于是文件的逻辑地址可以表示为（逻辑块号，块内地址）的形式。

操作系统为文件分配存储空间都是以块为单位的

用户通过逻辑地址操作自己的文件，操作系统要负责实现从逻辑地址到物理地址的转换。

**文件分配方式**

1. 连续分配

   连续分配要求每个文件在磁盘上占有一组连续的块

   用户给出要访问的逻辑块号，操作系统找到该文件对应的目录项（FCB）

   物理块号=起始块号+逻辑块号

   `支持直接访问和顺序访问`

   优点：连续分配的文件在顺序读/写时速度最快

   缺点：连续分配的文件不方便扩展；存储空间利用率低，会产生难以利用的磁盘碎片

2. 链接分配

   采用离散分配的思想，可以为文件分配离散的磁盘块。分为隐式链接和显式链接两种。

   - 隐式链接

     除了文件的最后一个磁盘块之外，每个磁盘块中都会保存指向下一个磁盘块的指针，这些指针对用户是透明的

     优点：很方便文件拓展，不会有碎片问题，外存利用率高

     缺点：只支持顺序访问，不支持随机访问，查找效率低

   - 显式链接

     把用于链接文件各物理块的指针显式地存放在一张表中，即文件分配表（FAT）

     注意：一个磁盘仅设置一张FAT，开机时，将FAT读入内存，并常驻内存。（不需要读磁盘操作）

     优点：很方便文件拓展，不会有碎片问题，外存利用率高，并且支持随机访问。

     缺点：文件分配表需要占用一定的存储空间。

3. 索引分配

   允许文件离散地分配在各个磁盘中，系统会为每个文件建立一张索引表，索引表中记录了文件各个逻辑块对应的物理块。

   索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块。

   在显式链接中，文件分配表FAT是一个磁盘对应一张。而索引分配方式中，索引表是一个文件对应一张。

   用户要访问的逻辑块号i，操作系统找到该文件的FCB，从目录项中可知索引表存放的位置，将索引表从外存读入内存，并查找索引表即可知道i号逻辑块在外存中的存放位置。

   - 链接方案

     查找效率低

   - 多层索引

     即使是一个小文件，访问一个数据块依然需要K+1次读磁盘

   - 混合索引

     一个文件的顶级索引表中，既包含直接地址索引，又包含一级间接索引，还包含二级间接索引

     优点：对于小文件来说，访问一个数据块所需的读磁盘次数更少

#### 4.2.4 文件存储空间管理

**存储空间的划分与初始化**

存储空间的划分：将物理磁盘划分为一个个文件卷（逻辑卷、逻辑盘）比如C、D盘

存储空间的初始化：将各个文件卷划分为目录区、文件区

目录区主要存放文件目录信息（FCB）、用于磁盘存储空间管理的信息

文件区用于存放文件数据

**存储空间管理**

- 空闲表法

  适用于连续分配方式

  - 分配：可采用首次适应、最佳适应、最坏适应
  - 回收：回收时需要注意表项的合并

- 空闲链表法

  - 空闲盘块链：以盘块为单位组成一条空闲链

    分配：若某文件申请K个盘块，则从链头开始依次摘下K个盘块分配，并修改空闲链的链头指针

    回收：回收的盘块依次挂到链尾，并修改空闲链的链尾指针

  - 空闲盘区链：以盘区为单位组成一条空闲链

    分配：首次适应、最佳适应等算法

    回收：若回收区与空闲盘区相邻则合并；不相邻则挂到链尾

- 位示图法

  每个二进制位对应一个盘块。可以用0代表盘块空闲，1代表盘块已分配。

  分配：若文件需要K个块。

  - 顺序扫描位示图，找到K个相邻或不相邻的0
  - 根据字号和位号算出对应的盘块号，将相应的盘块分给文件
  - 将相应位设置为1

  回收：

  - 根据回收的盘块号计算对应的字号、位号
  - 将相应的二进制位设为0

- 成组链接法

  文件卷的目录当中专门用一个磁盘块作为“超级块”，当系统启动时需要将超级块读入内存。并且要保证内存与外存中的超级块数据一致。

### 4.3 文件操作

#### 4.3.1 文件的基本操作

1. 创建文件（Create）

   参数

   - 所需的外存空间大小
   - 文件存放路径
   - 文件名

   执行操作

   - 找到文件所需的空间
   - 创建该文件的目录项

2. 删除文件（Delete）

   参数

   - 文件存放路径
   - 文件名

   执行操作

   - 找到文件名对应的目录项
   - 回收文件占用的磁盘块
   - 删除文件的目录项

3. 打开文件（open）

   参数

   - 文件存放路径
   - 文件名
   - 要对文件的操作类型

   执行操作

   - 找到文件名对应的目录项‘
   - 将目录项复制到内存中的打开文件表中，用户使用打开文件表的编号来指明要操作的文件

4. 关闭文件（close）

   执行操作

   - 将进程的打开文件表相应表项删除
   - 回收分配给该文件的内存空间等资源
   - 系统打开文件表的打开计数器count减1，若count=0，则删除对应表项

5. 读文件（read）

   参数

   - 指明是哪个文件（文件在打开文件表中的索引号即可）
   - 指明读入多少数据
   - 指明读入数据在内存中什么位置

   执行操作

   - 从读指针指向的外存中，将用户指定大小的数据读入用户指定的内存区域中

6. 写文件（write）

   参数

   - 指明是哪个文件（文件在打开文件表中的索引号即可）
   - 指明写多少数据
   - 写回外存的数据放在内存中的什么位置

   执行操作

   - 会从用户指定的内存区域中，将指定大小的数据写回写指针指向的外存

#### 4.3.2 文件共享

操作系统为用户提供文件共享功能，可以让多个用户共享地使用同一个文件

多个用户共享**同一个文件**，意味着系统只有一份文件数据，并且只要某个用户修改了该文件的数据，其他用户也可以看到文件数据的变化

**基于索引结点的共享方式（硬链接）**

**索引结点：**我们在查找文件时，通常最关心的只有文件名，所以可以把其他的一些信息存放到索引结点中，目录表中只存放文件名和指向索引结点的指针。

索引结点设置一个**链接计数器变量**，用于**表示链接到本索引结点上的用户目录项数。**

不同的用户可以对同一个共享文件的命名不同，但是它们指向的是同一个文件物理地址（索引结点）

若某个用户决定删除该文件，则只是把用户目录中与该文件对应的目录项删除，且索引结点上的计数器值减一

除非计数器值为0，否则不能把文件数据删除

**基于符号链的共享方式（软链接）**

类似于win下的快捷方式（Link类型文件）

当一个新用户访问文件时，操作系统会判断文件属于"Link"类型文件（软链接），于是会根据其中记录的路径层层查找目录，最终找到其链接用户中的目标文件表项，于是就找到了目标文件的索引结点。

删除Link类型文件不会影响目标文件（它只是一个快捷方式）

即使软链接指向的共享文件已被删除，Link类型文件依然存在，只是通过Link型文件中的路径去查找共享文件会失败（找不到对应目录项）

用软链接的方式访问共享文件需要查询多级目录，会有多次磁盘I/O，因此用软链接访问

#### 4.3.3 文件保护

1. 口令保护

   为文件设置一个口令，用户请求访问该文件时必须提供口令。

   优点：保存口令的文件开销不多，验证口令的时间开销也很小。

   缺点：正确的口令存放在系统内部，不够安全。

2. 加密保护

   使用某个密码对文件进行加密，在访问文件时需要提供正确的密码才能对文件进行正确的解密。

   优点：保密性强，不需要在系统中存储密码

   缺点：编码/译码，或者说加密/解密需要花费一定时间

3. 访问控制

   在每个文件的FCB中增加一个访问控制列表（ACL），该表中记录了各个用户可以对该文件执行哪些操作

   访问类型：读、写、执行、添加、删除、列表清单

   精简的访问列表：以“组”为单位，标记各组用户可以对文件执行哪些操作。

   如：分为系统管理员、文件主、文件主的伙伴、其他用户几个分组

   当用户想要访问文件时，系统会检查用户所属分组是否有相应的访问权限

### 4.4 文件结构

#### 4.4.1 文件系统结构层次

#### 4.4.2 磁盘的结构

**磁盘：**磁盘的表面由一些磁性物质组成，可以用这些磁性物质来记录二进制数据

**磁道：**磁盘的盘面被划分成一个个磁道，一个圈就是一个磁道

**扇区：**一个磁道划分成一个个扇区，每个扇区就是一个磁盘块，各个扇区存放的数据量相同

最内侧的扇区数据密度是最大的

**如何在磁盘中读/写数据**

需要把”磁头“移动到想要读写的扇区所在的磁道，磁盘会转起来，让目标扇区从磁头下面划过，才能完成对扇区的读/写操作。

**盘面：**磁盘中存在若干个盘面，一个磁片可能会有两个磁面。

每个盘面对应一个磁头，所有的磁头方向共进退

**柱面：**所有盘面中相对位置相同的磁道组成柱面

可用（柱面号，盘面号，扇区号）来定位任意一个磁盘块。

**根据地址读取一个块**

- 根据柱面号移动磁臂，让磁头指向指定柱面
- 激活指定盘面对应的磁头
- 在磁盘旋转过程中，指定的扇区会从磁头下面划过，这样就完成了对指定扇区的读/写。

**磁盘的分类**

- 按照磁头是否可以移动

1. 磁头可以移动的称为活动头磁盘。磁臂可以来回伸缩来带动磁头定位磁道

2. 磁头不可移动的称为固定头磁盘。这种磁盘中每个磁道有一个磁头

- 按照盘片是否可以更换

1. 可换盘磁盘
2. 固定盘磁盘

#### 4.4.3 磁盘调度算法

**一次磁盘读写操作需要的时间**

- 寻找时间（寻道时间）T~s~：在读/写数据前，将磁头移动到指定磁道所要花的时间
  - 启动磁头臂需要时间
  - 移动磁头需要花费时间
- 延迟时间T~R~：通过旋转磁盘，使磁头定位到目标扇区所需要的时间，与磁盘转速有关
- 传输时间T~t~：从磁盘读出或向磁盘写入数据所经历的时间，与磁盘转速有关

**磁盘调度算法**

优化寻道时间

1. **先来先服务算法（FCFS）**

   根据进程请求访问磁盘的先后顺序进行调度

   优点：公平；如果请求访问的磁道比较集中的话，算法性能还算过的去

   缺点：如果有大量进程竞争使用磁盘，请求访问的磁道很分散，则FCFS性能上很差，寻道时间长

2. **最短时间优先（SSTF）**

   优先处理的磁道是与当前磁头最近的磁道，可以保证每次的寻道时间最短，但是并不能保证总的寻道时间最短。

   优点：性能较好，平均寻道时间短

   缺点：可能产生饥饿现象（磁头在小区域内来回移动）

3. **扫描算法（SCAN）**

   为了防止SSTF算法产生饥饿的现象，可以规定，只有磁头移动到最外侧磁道的时候才能往内移动，移动到最内侧磁道的时候才能往外移动。由于磁头移动的方式很像电梯，因此也叫电梯算法。

   优点：性能较好，平均寻道时间较短，不会产生饥饿现象

   缺点：只有到达最边上的磁道时才能改变磁头移动方向；对于各个位置磁道的响应频率不平均

4. **LOOK调度算法**

   LOOK算法就是为了改进SCAN算法缺点1，如果在磁头移动方向上已经没有别的请求，就可以立即改变磁头移动方向

   优点：与SCAN做比较，不需要每次移动到最外侧才改变磁头方向，使寻道时间进一步缩短

5. **循环扫描算法（C-SCAN）**

   为了解决SCAN算法第二个缺点，规定只有磁头朝某个特定方向移动时才处理磁道访问请求，而返回时直接快速移动至起始端而不做任何请求。

   优点：相比于SCAN，对于各个位置磁道的响应频率很平均

   缺点：平均寻道时间长

6. **C-LOOK算法**

   C-SCAN算法的主要缺点是只有到达最边上的磁道时才能改变磁头移动方向，并且磁头返回时不一定需要返回最边缘的磁道上。

   C-LOOK算法就是为了解决这些问题，如果磁头移动的方向上已经没有磁道访问了，就可以立即让磁头返回，并且磁头只需要返回到有磁道访问请求的位置即可。

   优点：寻址时间进一步缩短

> 通常情况下可以分为四种调度算法，SCAN和LOOK归为一种，C-SCAN和C-LOOK归为一种

#### 4.4.4 减少延迟时间的方法

磁头读入一个扇区数据后需要一小段时间处理，如果逻辑上相邻的扇区物理上也相邻，则读入几个连续的逻辑扇区，可能需要很长的“延迟时间”。

**方法：交替编号**

让逻辑上相邻的扇区在物理上也有一定的间隔，可以使读取连续的逻辑扇区所需要的延迟时间更小

**磁盘地址结构设计**

若物理结构为（盘面号，柱面号，扇区号），可能会增加启动磁头臂的次数，将磁头移动到下一个磁道（柱面）（比如：(00，000，000)～(00，001，111)）

若物理结构为（柱面号，盘面号，扇区号），如果我们仍然需要读取(00，000，000)～(00，001，111)，只需要转动一圈，多启动一个磁头即可。

所以采用物理结构（柱面号，盘面号，扇区号），减少磁头移动消耗的时间

**错位命名**

让相邻盘面扇区编号错位，从而减少延迟时间

#### 4.4.5 磁盘管理

**磁盘初始化**

- 将磁盘的各个磁道划分为扇区，一个扇区由头、数据区域、尾三部分组成

- 将磁盘分区，每个分区由若干个柱面组成
- 逻辑格式化，创建文件系统

**引导块**

计算机开机时需要进行一系列初始化工作通过执行初始化程序（自举程序）完成的

完整的自举程序放在磁盘的启动块上，启动块位于磁盘的固定位置

拥有启动分区的磁盘称为启动磁盘或物理磁盘

**坏块**

无法正常使用的扇区就是“坏块”，这属于硬件故障，操作系统是无法修复的，应该将坏块标记出来，以免错误的使用到它

对于简单磁盘，在逻辑格式化时，对整个磁盘进行坏块检查，标明哪些扇区是坏扇区

对于复杂磁盘，磁盘控制器会维护一个坏块链表

## 5. I/O设备管理

### 5.1 I/O设备的概念和分类

**IO设备**

“I/O”就是“输入输出”

I/O设备就是可以将数据输入到计算机，或者可以接收计算机输出数据的外部设备，属于计算机中的硬件部件。

输入---鼠标、键盘

输出---显示器

输入、输出---移动硬盘

UNIX系统将外部设备抽象为一种特殊的文件，用户可以使用与文件操作相同的方式对外部设备进行操作。

**IO设备分类**

1. 按使用特性分类

- 人机交互类外部设备（用于人机交互）

  数据传输慢

  鼠标、键盘、打印机等

- 存储设备（用于数据存储）

  数据传输快

  移动硬盘、光盘等

- 网络通信设备（用于网络通信）

  传输速度介于上面两者之间

  调制解调器等

2. 按信息交换的单位分类

- 块设备

  传输速率较高，可寻址，即对它可随即地读/写任一块

  如磁盘等，数据传输的基本单位是块

- 字符设备

  传输速度慢，不可寻址，在输入/输出时常采用中断驱动方式

  鼠标、键盘等，数据传输的基本单位是字符

### 5.2 I/O控制器

I/O设备的机械部件主要用来执行I/O操作

I/O设备的电子部件通常是一块插入主板插槽的印刷电路板

**I/O设备的电子部件（I/O控制器）**

CPU无法直接控制I/O设备的机械部件，因此I/O设备还需要一个电子部件作为CPU和I/O设备机械部件之间的中介，用于实现CPU对设备的控制。

这个电子部件就是I/O控制器。CPU可控制I/O控制器，又由I/O控制器来控制设备的机械部件。

**I/O控制器的功能**

1. 接受和识别CPU发出的命令

   CPU发来的read/write命令，I/O控制器中会有相应的控制寄存器来存放命令和参数

2. 向CPU报告设备的状态

   I/O控制器中会有相应的状态寄存器，用于记录I/O设备的当前状态

3. 数据交换

   I/O控制器中会有相应的数据寄存器。输出时，数据寄存器用来暂存CPU发出来的数据，之后再由控制器传送设备。输入时，数据寄存器用于暂存设备发来的数据，之后CPU数据寄存器取走数据。

4. 地址识别

   为了区分设备（I/O）控制器中的各个寄存器，也需要给各个寄存器设置一个特定的地址。I/O控制器通过CPU提供的地址来判断CPU要读/写的是哪个寄存器。

**I/O控制器的组成**

1. CPU与控制器的接口

2. I/O逻辑

   负责接收和识别CPU的各种命令，并负责对设备发出命令

3. 控制器与设备的接口

### 5.3 I/O控制方式

**程序直接控制方式**

- CPU干预的频率很频繁，I/O操作开始之前、完成之后都需要CPU介入，并且在等待I/O完成的过程中CPU 需要不断地轮询检查

- 数据传送的单位：每次读/写一个字

- 数据的流向

  读操作（数据输入）：I/O设备->CPU->内存

  写操作（数据输出）：内存->CPU->I/O设备

  每个字的读/写都需要CPU帮助

- 主要优缺点

  优点：实现简单

  缺点：CPU和I/O只能串行工作，CPU需要一直轮询检查，长期处于“忙等”状态，CPU利用率低。

**中断驱动方式**

由于I/O设备速度很慢，因此在CPU发出读/写命令后，可将等待I/O的进程阻塞，先切换到别的进程执行。

- CPU干预频率

  等待I/O完成的过程中CPU可以切换到别的进程执行

- 数据传送的单位：每次读/写一个字

- 数据的流向

  读操作（数据输入）：I/O设备->CPU->内存

  写操作（数据输出）：内存->CPU->I/O设备

  每个字的读/写都需要CPU帮助

- 主要优缺点

  优点：CPU和I/O设备可以并行的工作

  缺点：频繁的中断处理会消耗较多的CPU时间

**DMA方式**（直接存储器存取）

- 数据传送单位是块
- 数据的流向是从设备直接放入内存，或者从内存直接到设备
- 仅在传送一个或多个数据块的开始和结束时，才需要CPU干预

**通道控制方式**

**通道：**一个硬件，可以识别并执行一系列通道指令（弱鸡版的CPU）

- CPU干预率：极低，一次扔给通道一堆任务
- 数据传送单位：每次读/写一组数据块

- 数据的流向

  读操作（数据输入）：I/O设备->CPU->内存

  写操作（数据输出）：内存->CPU->I/O设备

### 5.4 I/O软件层次结构

1. **用户层软件**

实现了与用户交互的接口，用户可直接使用该层提供的、与I/O操作相关的库函数对设备进行操作

用户层软件将用户请求翻译成格式化的I/O请求，并通过系统调用请求操作系统内核的服务

2. **操作系统内核部分（I/O核心子系统）**

- 设备独立性软件

  又称设备无关性软件，与设备硬件特性无关的功能几乎都在这一层实现

  功能：

  - 向上提供统一的调用接口

  - 设备的保护

  - 差错处理

  - 设备的分配与回收

  - 数据缓冲区管理

  - 建立逻辑设备名到物理设备名的映射关系，根据设备类型选择调用相应的驱动程序

    设备独立性软件需要通过“逻辑设备表（LUT）”来确定逻辑设备对应的物理设备，并找到该设备对应的设备驱动程序

- 设备驱动程序

  主要负责对硬件设备的具体控制，将上层发出的一系列命令转换成特定设备能听得懂的一系列操作。包括设备寄存器；检查设备状态等

  不同的I/O设备有不同的硬件特性，具体细节只有设备的厂家知道。因此厂家需要根据设备的硬件特性设计并提供相应的驱动程序

- 中断处理程序

  当I/O任务完成时，I/O控制器会发送一个中断信号，系统会根据中断信号类型找到相应的中断处理程序并执行。

3. **硬件**

****

**I/O调度：用某种算法确定一个好的顺序来处理I/O请求**

**设备保护：**将设备看作是一种特殊的文件，操作系统会实现文件保护功能，不同的用户对各个文件有不同的访问权限。

### 5.5 假脱机技术（SPOOLing技术）

**脱机技术**

批处理阶段引入了脱机技术/输出技术（用磁带完成）：在外围控制机的控制下，慢速输入设备的数据先被输入到更快速的磁带上，之后主机可以从快速的磁带上读入数据。

脱机：脱离主机的控制进行的输入/输出操作

**假脱机技术---输入井和输出井**

又称“SPOOLing技术”，**是用软件的方式模拟脱机技术。**

要实现SPOOLing技术，必须有多道程序技术的支持。系统会建立输入进程和输出进程

**SPOOLing技术作用**

**可以把一台物理设备虚拟成逻辑上的多台设备，可将独占式设备改造成共享设备**

独占式设备：只允许各个进程串行使用的设备

共享式设备：允许多个进程同时使用的设备

### 5.6 设备的分配与回收

**设备分配时应该考虑的因素**

1. 设备的故有属性

   独占设备、共享设备、虚拟设备（采用SPOOLing技术）

2. 设备分配算法

   先来先服务、优先级优先、短任务优先等

3. 设备分配中的安全性

   - 安全分配方式：为进程分配一个设备后就将进程阻塞，本次I/O完成后才将设备唤醒

     一个时间段内只能使用一个设备

     优点：破坏了“请求和保持”条件，不会死锁

     缺点：对于一个进程来说，CPU和I/O设备只能串行工作

   - 不安全分配方式：进程发出请求后，系统为其分配I/O设备，进程可继续执行，之后还可以发出新的I/O请求。只有某个I/O请求得不到满足才将进程阻塞。

     一个进程可以同时使用多个设备

     优点：进程的计算任务和I/O任务可以并行处理i，使进程迅速推进

     缺点：有可能发生死锁

**静态分配和动态分配**

**静态分配：**进程运行前为其分配全部所需资源，运行结束后归还资源

**动态分配：**进程运行过程中动态申请设备资源

**设备管理中的数据结构**

**设备控制表（DCT）：**系统为每个设备配置一张DCT，用于记录设备情况

设备类型、设备标识符、设备状态、指向控制器表的指针、重复执行次数或时间、设备队列的队首指针

**控制器控制表（COCT）：**每个设备控制器都会对应一张COCT。操作系统根据COCT的信息对控制器进行操作和管理

控制器标识符、控制器状态、指向通道表的指针、控制器队列的队首指针、控制器队列的队尾指针

**通道控制表（CHCT）：**每个通道都会对应一张CHCT。操作系统根据CHCT的信息对通道进行操作和管理

通道标识符、通道状态、与通道连接的控制器表首址、通道队列的队首指针、队尾指针

**系统设备表（SDT）：**记录了系统中全部设备的情况，每个设备对应一个表目

设备类型、设备标识符、DCT、驱动程序入口

**设备分配步骤**

### 5.7 缓冲区管理

**缓冲区**

缓冲区是一个存储区域，可以由专门的硬件寄存器组成，也可以利用内存作为缓冲区

使用硬件作为缓冲区的成本较高、容量也较小，一般仅用在对速度要求非常高的场合

一般情况下，更多的是利用内存作为缓冲区，“设备独立性软件”的缓冲区管理就是要组织管理好这些缓冲区

**缓冲区特点**

当缓冲区数据非空时，不能向缓冲区冲入数据，只能从缓冲区把数据传出

当缓冲区为空时，可以向缓冲区冲入数据，但必须把缓冲区充满以后，才能从缓冲区把数据传出

**作用**

1. 缓和CPU和I/O设备之间速度不匹配的矛盾

   CPU可以把要输出的数据快速地放入缓冲区，之后就可以做别的事

   慢速的I/O设备可以慢慢从缓冲区取走数据

2. 减少CPU中断频率，放宽对CPU中断相应时间的限制

   如果是字符型设备，则每输出一个字符就要像CPU发送一次中断信号

3. 解决数据粒度不匹配的问题

   输出进程每次可以生成一块数据，但I/O设备每次只能输出一个字符（将缓冲区作为中转）

4. 提高CPU与I/O设备的并行性

**单缓冲、双缓冲、循环缓冲区、缓冲池**

若实现数据之间的双向传输，可以配置两个缓冲区用于数据的发送和接收



